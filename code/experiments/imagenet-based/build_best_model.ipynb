{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with best hyperparameters & save pretrained model\n",
    "\n",
    "Saving models not done in experiment.py to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20\n",
      "----------\n",
      "train Loss: 1.1559 Acc: 0.5851\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 1.0139 Acc: 0.7318\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.9853 Acc: 0.7502\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.9287 Acc: 0.8199\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.9028 Acc: 0.8448\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.9151 Acc: 0.8264\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.8815 Acc: 0.8672\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.8483 Acc: 0.9007\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.8483 Acc: 0.8974\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.8448 Acc: 0.9027\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.8432 Acc: 0.9001\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.8436 Acc: 0.9060\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.8436 Acc: 0.9080\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.8431 Acc: 0.9001\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.8326 Acc: 0.9211\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.8409 Acc: 0.9093\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.8364 Acc: 0.9119\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.8412 Acc: 0.9040\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.8377 Acc: 0.9106\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.8401 Acc: 0.9086\n",
      "\n",
      "Final train accuracy: 0.908613\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "from torch.optim import lr_scheduler\n",
    "import mlflow\n",
    "import json\n",
    "import sys\n",
    "\n",
    "json_filename = './final_script/best_hyperparams.json'\n",
    "experiment = '123_vertical_split'\n",
    "\n",
    "try:\n",
    "    with open(f'{json_filename}', 'r') as file:\n",
    "        experiment_data = json.load(file)\n",
    "except (json.decoder.JSONDecodeError, FileNotFoundError) as e:\n",
    "    print(f'Invalid experiments.json, aborting: {e}')\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    imagefolder_path = experiment_data['imagefolder_path']\n",
    "except (AttributeError, KeyError) as e:\n",
    "    print(f'Invalid imagefolder path: {e}')\n",
    "    exit()\n",
    "\n",
    "for parameters in experiment_data['experiments']:\n",
    "    # hyperparameters, tag\n",
    "    try:\n",
    "        NUM_EPOCHS = parameters['NUM_EPOCHS']\n",
    "        BATCH_SIZE = parameters['BATCH_SIZE']\n",
    "        LAYERS_TRAINED = parameters['LAYERS_TRAINED']\n",
    "        LEARNING_RATE = parameters['LEARNING_RATE']\n",
    "        MOMENTUM = parameters['MOMENTUM']\n",
    "        RANDOM_SEED = parameters['RANDOM_SEED']\n",
    "        BASE_MODEL = parameters['BASE_MODEL']\n",
    "        TAG = parameters['TAG']\n",
    "    except (AttributeError, KeyError) as e:\n",
    "        print(f'Invalid data in experiments.json: {e}')\n",
    "        exit()\n",
    "\n",
    "    target_num_of_classes = 2 if experiment == 'upperlower' else (3 if experiment in ['MPI', '123'] else 4)\n",
    "\n",
    "    # set random seed for both CUDA and CPU with manual seed\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Grayscale(3),\n",
    "            transforms.GaussianBlur(3),\n",
    "            transforms.ColorJitter(brightness=[0.95,1.05], contrast=[0.8,1.2]),\n",
    "            transforms.RandomAffine(degrees=[-5,5], shear=(1,10,1,10), fill=255),\n",
    "            transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Grayscale(3),\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    data_dir = f'{imagefolder_path}/{experiment}'\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                            data_transforms[x])\n",
    "                    # for x in ['train', 'val']}\n",
    "                    for x in ['train']}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE,\n",
    "                                                shuffle=True, num_workers=0) # seed this random\n",
    "                # for x in ['train', 'val']}\n",
    "                for x in ['train']}\n",
    "    # dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train']}\n",
    "    class_names = image_datasets['train'].classes\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Model setup: load base model, replace last layer\n",
    "    # syntax depends on base model submodule structure & naming\n",
    "    if (BASE_MODEL == 'vit_b_16'):\n",
    "        model = torchvision.models.vit_b_16(weights='ViT_B_16_Weights.IMAGENET1K_V1')\n",
    "        num_ftrs = model.heads[0].in_features\n",
    "        model.heads[0] = nn.Linear(num_ftrs, target_num_of_classes)\n",
    "\n",
    "    elif (BASE_MODEL == 'alexnet'):\n",
    "        model = torchvision.models.alexnet(weights='AlexNet_Weights.IMAGENET1K_V1')\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs, target_num_of_classes)\n",
    "\n",
    "    elif (BASE_MODEL == 'efficientnet_v2_s'):\n",
    "        model = torchvision.models.efficientnet_v2_s(weights='EfficientNet_V2_S_Weights.IMAGENET1K_V1')\n",
    "        num_ftrs = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_ftrs, target_num_of_classes)\n",
    "\n",
    "    elif (BASE_MODEL == 'vgg16'):\n",
    "        model = torchvision.models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1')\n",
    "        num_ftrs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_ftrs, target_num_of_classes)\n",
    "\n",
    "    elif (BASE_MODEL == 'densenet121'):\n",
    "        model = torchvision.models.densenet121(weights='DenseNet121_Weights.IMAGENET1K_V1')\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, target_num_of_classes)\n",
    "    \n",
    "    elif (BASE_MODEL == 'resnet101'):\n",
    "        model = torchvision.models.resnet101(weights='ResNet101_Weights.IMAGENET1K_V2')\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, target_num_of_classes)\n",
    "    \n",
    "    else: \n",
    "        print('ERROR: unsupported base model, options: vit_b_16, alexnet, efficientnet_v2_s, vgg16, densenet121, resnet101')\n",
    "\n",
    "    # Freeze layers\n",
    "    if LAYERS_TRAINED != 'all':\n",
    "        for param in list(model.parameters())[:-1*(LAYERS_TRAINED)]:\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # Add softmax to end of net to get valid probabilities as outputs for confidence scores\n",
    "    model = nn.Sequential(\n",
    "        model,\n",
    "        nn.Softmax(1)\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    # loss & lr scheduling\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            # for phase in ['train', 'val']:\n",
    "            # Only train when building mpi and index models\n",
    "            for phase in ['train']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                \n",
    "                if phase == 'val':\n",
    "                    val_accuracies.append(epoch_acc.item())\n",
    "                    val_losses.append(epoch_loss)\n",
    "                if phase == 'train':\n",
    "                    train_accuracies.append(epoch_acc.item())\n",
    "                    train_losses.append(epoch_loss)\n",
    "\n",
    "            print()\n",
    "\n",
    "        # print(f'Final validation accuracy: {val_accuracies[-1]:4f}')\n",
    "        print(f'Final train accuracy: {train_accuracies[-1]:4f}')\n",
    "\n",
    "        # return model, train_accuracies, val_accuracies, train_losses, val_losses\n",
    "        return model, train_accuracies, train_losses\n",
    "\n",
    "    # model, train_accuracies, val_accuracies, train_losses, val_losses = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=NUM_EPOCHS)\n",
    "    model, train_accuracies, train_losses = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pt_filename = f'{experiment}_best.pt'\n",
    "torch.save(model, model_pt_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
