{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility scripts to organize data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add filename to v3,4,5 labels.txt\n",
    "\n",
    "versions = range(3,6)\n",
    "\n",
    "file_count = 0\n",
    "for v in versions:\n",
    "    df = pd.read_csv(f'/home/riikoro/fossil_data/tooth_samples/v{v}/labels.txt')\n",
    "    df['filename'] = df.index.astype('str') + '.png'\n",
    "    colnames = ['filename', 'tooth', 'u']\n",
    "    df = df.reindex(columns=colnames)\n",
    "    df['u'] = df['u'].astype('Int64') # int64 allows nans\n",
    "    print(df.head())\n",
    "    df.to_csv(f'/home/riikoro/fossil_data/tooth_samples/v{v}/labelsnew.txt', index=False)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels.txt files for v8-21, filename | tooth | u (to have labels similar w v3, v4)\n",
    "versions = range(8,22)\n",
    "base_path = f'/home/riikoro/fossil_data/tooth_samples/'\n",
    "\n",
    "for v in versions:\n",
    "    # read up low to df\n",
    "    df = pd.read_csv(f'{base_path}/v{v}/upper_lower_labels.txt', names=['filename', 'u'], header=0)\n",
    "    # print(df.head())\n",
    "\n",
    "    # read azure labels\n",
    "    azure_labels = pd.read_csv(f'{base_path}/v{v}/azure_labels.txt', header=None, names=['tooth'])\n",
    "    azure_labels['filename'] = azure_labels.index.astype('str') + '.png'\n",
    "    # print(azure_labels.head())\n",
    "\n",
    "    # azure labels contains labels for all images (also deleted images that are not tooth markings) --> merge by left join (drop azure labels where filename does not exist in df)\n",
    "    df = df.merge(azure_labels, on='filename', how='left')\n",
    "    df['u'] = df['u'].astype('Int64')\n",
    "    # reorder\n",
    "    colnames = ['filename', 'tooth', 'u']\n",
    "    df = df.reindex(columns=colnames)\n",
    "\n",
    "    df.to_csv(f'/home/riikoro/fossil_data/tooth_samples/v{v}/labels.txt', index=False)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label files with filename | azure_output | MPI | upper | index for all versions (labels_full.csv)\n",
    "base_path = f'/home/riikoro/fossil_data/tooth_samples/'\n",
    "versions = [3,4,5]\n",
    "versions.extend(list(range(8,22)))\n",
    "\n",
    "# function for removing invalid tooth indices\n",
    "def fix_tooth_labels(tooth, index):\n",
    "    # Fix index: set to none if mpi is c\n",
    "    # Fix index: number is something else than 1,2,3,4\n",
    "    # Fix index: mpi is m or i and index is 4\n",
    "    invalid_index = tooth == 'C' or (index not in ['1','2','3','4']) or (tooth in ['M', 'I'] and index not in ['1','2','3'])\n",
    "    new_index = None if invalid_index else index\n",
    "    return new_index\n",
    "\n",
    "for v in versions:\n",
    "    # read up low to df\n",
    "    df = pd.read_csv(f'{base_path}/v{v}/labels.txt', header=0, names=['filename', 'azure_output', 'u'])\n",
    "    df['u'] = df['u'].astype('Int64')\n",
    "\n",
    "    # Create MPI column, fill with azure outputs where output is m p or i. put none for where output is not mpi\n",
    "    df['MPI'] = df['azure_output'].str[0] # str to vectorize\n",
    "    df['MPI'] = df['MPI'].apply(lambda s: s.upper() if s.upper() in ['M', 'P', 'I', 'C'] else None)\n",
    "\n",
    "    # Create index column\n",
    "    df['tooth_index'] = df['azure_output'].str[-1] # last character to not get indexoutofbounds errors for c's\n",
    "    df['tooth_index'] = df.apply(lambda x: fix_tooth_labels(x.MPI, x.tooth_index), axis=1).astype('Int64')\n",
    "\n",
    "    # set c's to none in mpi column\n",
    "    df.to_csv(f'{base_path}/v{v}/labels_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
