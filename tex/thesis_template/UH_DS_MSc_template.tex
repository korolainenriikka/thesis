%% Final edits by Jussi Kangasharju and Pirjo Moen
%% This file is modified by Veli Mäkinen from HY_fysiikka_LuKtemplate.tex authored by Roope Halonen ja Tomi Vainio.
%% Some text is also inherited from engl_malli.tex by Kutvonen, Erkiö, Mäkelä, Verkamo, Kurhila, and Nykänen.


% STEP 1: Choose oneside or twoside
\documentclass[english,twoside,openright]{UH_DS_MSc}
%finnish,swedish

%\usepackage[utf8]{inputenc} % For UTF8 support. Use UTF8 when saving your file.
\usepackage{lmodern} % Font package
\usepackage{textcomp} % Package for special symbols
\usepackage[pdftex]{color, graphicx} % For pdf output and jpg/png graphics
\usepackage[pdftex, plainpages=false]{hyperref} % For hyperlinks and pdf metadata
\usepackage{fancyhdr} % For nicer page headers
\usepackage{tikz} % For making vector graphics (hard to learn but powerful)
%\usepackage{wrapfig} % For nice text-wrapping figures (use at own discretion)
\usepackage{amsmath, amssymb} % For better math
%\usepackage[square]{natbib} % For bibliography
\usepackage[footnotesize,bf]{caption} % For more control over figure captions
\usepackage{blindtext}
\usepackage{titlesec}
\usepackage[titletoc]{appendix}
\usepackage[nodayofweek,level]{datetime}
%\usepackage[USenglish]{babel}
\newcommand{\thesisdate}{\formatdate{19}{12}{2024}}
\usepackage{algorithm}
\usepackage{algpseudocode}

\onehalfspacing %line spacing
%\singlespacing
%\doublespacing

%\fussy 
\sloppy % sloppy and fussy commands can be used to avoid overlong text lines

% STEP 2:
% Set up all the information for the title page and the abstract form.
% Replace parameters with your information.
\title{Fine-tuned optical character recognition for dental fossil markings}
\author{Riikka Korolainen}
\date{\thesisdate}
\prof{Professor Indr{\.e} \v{Z}liobait{\.e}}
%\censors{Professor A}{Dr. B}{}
\censors{}{}{}
\keywords{Optical character recognition, Transfer learning, Paleontological databases}
\depositeplace{}
\additionalinformation{}


\classification{\protect{\ \\
\  Computing methodologies  $\rightarrow$  Machine learning $\rightarrow$ Machine learning approaches $\rightarrow$ Neural Networks \  \\
\  Computing methodologies $\rightarrow$ Machine learning $\rightarrow$ Learning paradigms $\rightarrow$ Multi-task learning $\rightarrow$ Transfer learning \  \\
\  Applied computing $\rightarrow$ Physical sciences and engineering $\rightarrow$ Earth and atmospheric sciences \  \\
}}

% if you want to quote someone special. You can comment this line and there will be nothing on the document.
%\quoting{Bachelor's degrees make pretty good placemats if you get them laminated.}{Jeph Jacques} 


% OPTIONAL STEP: Set up properties and metadata for the pdf file that pdfLaTeX makes.
% But you don't really need to do this unless you want to.
\hypersetup{
    %bookmarks=true,         % show bookmarks bar first?
    unicode=true,           % to show non-Latin characters in Acrobat’s bookmarks
    pdftoolbar=true,        % show Acrobat’s toolbar?
    pdfmenubar=true,        % show Acrobat’s menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={},            % title
    pdfauthor={},           % author
    pdfsubject={},          % subject of the document
    pdfcreator={},          % creator of the document
    pdfproducer={pdfLaTeX}, % producer of the document
    pdfkeywords={something} {something else}, % list of keywords for
    pdfnewwindow=true,      % links in new window
    colorlinks=true,        % false: boxed links; true: colored links
    linkcolor=black,        % color of internal links
    citecolor=black,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\begin{document}

% Generate title page.
\maketitle

% STEP 3:
% Write your abstract (of course you really do this last).
% You can make several abstract pages (if you want it in different languages),
% but you should also then redefine some of the above parameters in the proper
% language as well, in between the abstract definitions.

\begin{abstract}

Digitizing and uniformizing the structure of handwritten fossil catalogues exhibits a great 
potential for increasing the accuracy of paleontological data analysis by increasing sample sizes. 
Approximately 90, 000 of such samples reside in the archives of the National Museum of Kenya, and 
an ongoing effort is to store this data in a digital format for better accessibility.
A previous project utilized a commercial optical character recognition service for automated reading of these catalogues. This generalist
handwriting detection model lacked the ability to detect special characters used to denote tooth samples, and could not utilize prior knowledge 
of the vocabulary that is more likely to be present in the data, leading to loss of information and detection mistakes.

This thesis aims to build a specialist character recognition model to increase the accuracy of 
the bone or tooth type specifying column of the digitized data by fine-tuning a state-of-the-art optical 
character recognition model with few-shot transfer learning. This is performed by first finding most accurate
recognition models, variants of convolutional neural networks or vision transformers, and most successful 
transfer learning methods for adapting a model to a new character set. Then, the character 
recognition accuracy of combinations of these methods are benchmarked using handlabeled image segments from the 
fossil catalogues. The final aim of this work is to use the best-performing model 
to obtain an accurate reading of the catalogues of the National Museum of Kenya, and publish the final model to be used 
by the paleontological community for further digitization efforts.

\end{abstract}

% Place ToC
\mytableofcontents

\mynomenclature

% -----------------------------------------------------------------------------------
% STEP 4: Write the thesis.
% Your actual text starts here. You shouldn't mess with the code above the line except
% to change the parameters. Removing the abstract and ToC commands will mess up stuff.
\chapter{Introduction}

The field of paleoecology conducts data analysis on fossil specimens.
Such analysis is quite literally started from the ground: after a fossil specimen has been found, it is 
carefully measured and identified: which bone and species the fragment is from, and how old it is. On site, such information is logged on field slips, small thin sheets of 
paper with a pre-printed form. The analysis has then been traditionally conducted by 
collecting such entries, sometimes collected in handwritten tabular catalogues, and running statistical 
tests on the sample set. With this analysis, facts from distant past, such as climate, habitats and 
vegetation can be deduced \cite{Faith_Lyman_2019}. Syntheses of such results consequently allow us to 
answer larger questions, such as how ecosystems reacted to climate changes, how mass extinction events 
came about, and what the living world could be like \cite{Zliobaite2023}. Understandably, answering such 
questions has become ever more pressing.

To find answers to large-scale problems, more sophisticated computational data analysis methods have come about,
relying on large datasets. Due to the infeasibility of collecting stacks of fields slips across sometimes multiple 
continents, specimens residing in archives of institutions have been converted to digital, public databases.
One such institution is the National Museum of Kenya that holds a large fraction of data collected from one 
of the most valuable fossil sites globally, the lake Turkana. The digitization effort was started by
using commercial optical character recognition software, combined with heuristical and machine learning approaches, 
resulting in satisfactory accuracy on conventional handwritten text. However, a large hurdle in the existing 
approach were the special characters used to denote which teeth each specimen contains. The aim of this work is 
to digitize these markings accurately.

Specifically, this work uses as input data both scan images of the fossil slips and catalogues, and outputs from the Azure AI Vision software \cite{azurevision}. The existing outputs consist of sentence and word-level readings, along with bounding boxes defining 
the location of each word or sentence. The main research question is the following: 

How, given the input data, can the accuracy of the readings of the tooth markings be improved?

The direct impact of this work is an improved precision of the tooth element entries in the digitized 
fossil catalogues of the National Museum of Kenya, but the results are applicable to a wider domain of problems.
Intuitively, the results are directly applicable to other fossil archives using similar notation: only a fine-tuning of the 
models to the new archival data is necessary.
For other handwritten archives, the results presented can be used to improve recognition accuracy, especially in cases 
where the data contains characters other than latin letters or arabic numerals. Additionally, this work presents
a potential solution for when the target character set can be expressed with multivariate output data. This could, for 
instance, be handwriting with occasional underlinings, where the bivariate output could be the letter and a boolean variable for 
whether the character was underlined.

The rest of this thesis is organized as follows. First, the necessary background theory is 
presented. For deep neural networks, the following concepts are introduced:
the basic network structure, how training is conducted, basic building blocks of character-recognizing network architectures, performance-improving 
heuristics, and transfer learning. For paleoecology, the background covers 
foundational ecological laws followed by a brief introduction to methods used in
paleoenvironmental reconstruction, especially focusing on inferences from tooth data.
As the last background section, the composition of mammal teeth is presented. 
Second, related work is presented, both on
handwritten archive digitization and transfer learning with character-recognizer models.
Next, the experimental setup is introduced, covering dataset creation, labeling and data 
preprocessing, followed by base model and transfer learning method selection. After this, 
results of the experiments are presented and discussed. Finally, the work is concluded.

\chapter{Fundamentals on paleoecology}

\section{Basics on ecology}

\section{Paleoenvironmental reconstruction}

\section{Composition of mammal teeth}

Since geological events tend to erode organic remains the faster the remain decomposes, the hardest materials in 
the corpse represent largest fractions of fossil datasets. These hard materials include shells, bones and especially teeth, and 
the last is prominent in fossil data analysis also due to the fact that they encode a diverse set of information on 
the livelihood of the organism \cite{Faith_Lyman_2019}. The identification of the fossil remain is done at the finest resolution possible,
preferring taxon information over just identifying the genus, for instance. Finest-resolution information 
derived from dental fossils are the taxon the tooth is from, and which tooth or teeth are found in the specimen.
This section presents the naming and indexing system for mammal teeth commonly used in paleontological datasets,
as described by Hillson \cite{Hillson_2005}, and some common shorthand versions present in the dataset digitized in this work.

Specimens including more complete fragments of the jaw are described with terminology related 
to the jaw bones. All mammals share the same bone structure around the mouth: the lower jaw consists 
of two bones called \textit{mandibles}, joining in the middle, whereas the upper jaw consists of bones called 
\textit{maxilla} and \textit{premaxilla}, that also form large parts of the face.
A common trait across many mammals is also that the permanent teeth erupt in the 
youth of the animal, replacing the 'milk' or \textit{decidous} teeth. Shorthands commonly used for these 
terms are 'mand' for mandibles, and capital letter 'D' for the decidous teeth.

The tooth rows of mammals are classified to four classes; \textit{incisor}, \textit{canine}, \textit{premolar}
and \textit{molar} and indexed with a numbering system. Moving from the middle of the tooth row
towards the side, there are up to three 
incisors, used for catching food and denoted with the letter 'i'. Behind them is the canine tooth, used for cutting, and 
in case of predators, killing. This tooth is denoted with the letter 'c'. Behind the canine are up to four premolars, noted with 'p'. These 
teeth vary most between taxa in form and function with functions including cutting, holding and chewing food.
The teeth at the back of the row are called molars, 'm', and are primarily used for chewing. Molars, like the other tooth types, 
vary in number between taxa, and are at most three. The numbers are always increasing when moving back in the tooth row, but in
 the case of missing teeth in a taxon, the numbers do not necessarily start from one: instead, the number is chosen to 
have teeth with same numbers as alike each other as possible. Thus, a taxon with only two premolars might only have the teeth P3 and P4.

Location of the tooth present in the fossil is described with directional terms specifying the side, jaw and the location on the jaw.
The most
intuitive are left and right describing the side, where one needs to note that each denotes the side from the viewpoint of the 
animal, not the observer. Mammal teeth are always symmetrical, thus every tooth always has the 
equivalent other-jaw counterpart. The distance of a tooth from the throat 
is described with the terms \textit{distal}, 'far from to the mouth' and \textit{mesial}, 'close to the mouth'. For skeletal bones, the term \textit{proximal}, 
'close to the center of the body' is often used instead of 'mesial'.
Short-form versions for these terms include capital 'L' or 'Lt' for left, capital 'R' or 'Rt' for right, 'dist.' 
for distal and 'prox' for proximal.
The jaw, upper or lower, has three dominant notation styles: one is to sub- or superscript tooth index numbers, other is to 
over- or underline tooth markings, and the last style, prominent in digital fossil data, is to set the tooth type letter to upper- or lowercase.
In each of these systems, a superscipt, underline, or capital letter denotes upper jaw, and conversely subscript, overline or lowercase letter denotes the lower jaw.
An illustration of the mammal tooth system is presented in Figure~\ref{image:mammal_teeth}. Terminology with corresponding shorthands are summarized in Table~\ref{table:terminology} and jaw notation styles in Table~\ref{table:jaw_notation}.

\begin{figure}[h]
    \centering
    \includegraphics*[scale=0.43]{teeth_img_hillson_book.png}
    \caption{Mammal teeth composition, from Hillson \cite{Hillson_2005}.}
    \label{image:mammal_teeth}
\end{figure}

\begin{table}[ht]
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Term}       & \textbf{Meaning}                                   & \textbf{Shorthands}       \\ \hline
        Mandible            & Lower jaw bone                                     & mand.                     \\ %\hline
        Maxilla, Premaxilla & Upper jaw bones                                    &                           \\ %\hline
        Deciduous           & 'Milk teeth'                                       & D, d                      \\ %\hline
        Incisor             & Tooth type (front, middle)                         & I, i                      \\ 
        Canine              & Tooth type (between incisor and premolar)          & C, c                      \\ %\hline
        Premolar            & Tooth type (between canine and molar)              & P, p                      \\ %\hline
        Molar               & Tooth type (back of tooth row)                     & M, m                      \\ %\hline
        Distal              & Far from body center / mouth                       & dist.                     \\ %\hline
        Mesial              & Close to the mouth                                 &                           \\ %\hline
        Proximal            & Close to body center                               & prox.                     \\ \hline
    \end{tabular}
    \caption{Terminology related to mammal teeth with corresponding shorthands}
    \label{table:terminology}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{|l|l|l|l|}
        \hline
        \textbf{Jaw}      & \textbf{Line Notation} & \textbf{Sub/Superscript Notation} & \textbf{Digital Notation} \\ \hline
        Upper         & $\text{M}^{\underline{1}}$      & m\textsuperscript{1}              & M1                        \\ 
        Lower         & $\text{M}_{\overline{1}}$ & m\textsubscript{1}                & m1                        \\ \hline
    \end{tabular}
    \caption{Dental marking styles, Example: first molar. Line notation displayed in common style combining sub- and superscripts.}
    \label{table:jaw_notation}
\end{table}

\chapter{Deep Neural Networks for Optical Character Recognition}

This chapter presents relevant background on deep neural networks (DNN), also known 
in literature as artificial neural networks (ANN) or, for historical reasons, multilayer perceptrons (MLP).
The aspects presented are constrained to those relevant to the problem at hand, optical character recognition (OCR),
that is also used as a running example.

\section{Deep Neural Networks}

Neural networks are multivariate functions that share a specific form.
The function parameters, usually floating-point numbers, are called weights and are organized in groups called layers.
The first layer is called the input layer, after which there are multiple hidden layers, followed by the output layer.
Weights of adjacent layers are combined by activation functions, that are constrained to nonlinear functions with 
scalar inputs and outputs \cite{princebook}. Simplest of the activation functions is the rectified
linear unit ReLU, shown in Equation~\ref{eq:relu}. A neural network is usually visualized with a graph structure, as seen in Figure TODO, where a node represents a 
weight, and an edge denotes that the value on the first layer is used to compute the value on the latter.

\begin{align}
\text{ReLU}(x) = \max(0, x)
\label{eq:relu}
\end{align}

% - feed forward
% network computes output from input with the feed forward.
% you have an input, bunch of numbers
% then, you compute a linear combination and pass that through an activation function 

The computation of an output based on an input in the network is called the 
feed-forward, as the computation runs forward layer by layer through the 
network. The process starts from the input layer, which is simply the input 
organized as a vector. Each intermediate value on the first hidden layer, noted $h_d$ below,
is computed by taking a linear combination of the layer weight vector $\mathbf{\theta}$ and 
the input vector $\mathbf{x}$ of size $N$, adding the 
bias term $\theta_0$, and passing the result through the activation function $a$:

\begin{align}
    h_d = a\left[ \theta_{0} + \sum_{i=1}^{N}\theta_{di}x_{i} \right]
\label{eq:fc_layer}
\end{align}

Different types of layers, such as convolutional or transformer layers 
denote that this single-layer computation process is performed differently from 
the standard form. When many layer types are present, layers using the computation
in Equation~\ref{eq:fc_layer} are called fully connected or dense layers.

The computation proceeds from the first hidden layer in a similar manner: 
the next layer values, also called activations, are computed using the weights of 
the layer and the previous layer activations with Equation~\ref{eq:fc_layer}.
The activations of the output layer is the output of the network.
More complex networks are generally constructed by increasing the network size to up to 
hundreds of layers with hundreds of millions of parameters, and by using
different types of layers.

The universal function approximator theorem states that functions belonging to the 
neural network family are capable of approximating any mapping from any type or shape of input
to any output with arbitrary precision \cite{princebook}. Naturally, due to high computational 
costs of finding the optimal weights and the large search space of possible networks, 
this theoretical optimum is rarely reached.

Examples of input-output mappings relevant in this work are the following, 
ordered from simplest to most complex: tooth type classification, constrained multilabel classification, 
and sequence-to-sequence learning. The problem of tooth type classification takes in an input image of a dental marking,
such as input in Figure TODO a, and decides which tooth the image denotes.
As mammals have up to eleven teeth on each side of two jaws, the classes would be 
these 44 teeth, such as 'rm1', 'lP4' or 'li2', using the computational notation presented in
Section TODO ref mammal teeth. The network would output a 44-element discrete probability distribution 
obtained by using the softmax function~ref{eq:softmaxTODO}, where each value notes the probability that the image contains 
the tooth this value is chosen to represent. The final output would then be the largest probability
found in this vector.

A better approach that could encode the fact that all teeth of same type share a similar input feature
, a letter in the image, could be formulating the problem as a multilabel
problem \cite{multilabel_classification}: the output would be three of the aforementioned 
probability vectors, one with four elements representing 'M', 'P', 'C' or 'I', one with four elements 
for tooth indices, and two two-element vectors for left-right and upper-lower jaw. As this 
formulation lacks the notion that some tooth-type pairs never exist, such as the 4th canine,
this is a case of constrained multiclass classification, where some label pairs are marked 
as impossible combinations.

Generalizing the mapping problem further, one could also input a variable-length image 
of the entire dental marking comprising of multiple words, and outputting the text on this image.
Due to the variable output length, a special technique called sequence-to-sequence learning 
is employed \cite{sutskever2014sequence}. This encodes the fixed-length output layer to variable-length 
output text. Even though all of the problems presented in this section recognize characters, 
generally the term 'optical character recognition' is used for this type of mapping. Models
for solving these problems accurately are very large, for instance the Microsoft TrOCR has approximately 
500,000 parameters \cite{li2021trocr}.

Finding the best network weights for any of these types of input/output mapping problems, training 
a network, is conducted with the same process.
The general recipe for training a neural network is the subject of the next section.

\section{Training neural networks}

After one has defined a neural network structure, initialized the weights of the network 
to some initial values and obtained a sufficiently large set of input-output pairs from the problem at hand,
one can start training the network. Training is an iterative process where inputs are used to 
predict the output, which is then compared to the ground truth. A more detailed account of these iterations
is presented next.

At the start of training, a small fraction, commonly 10-20\%, is reserved as test data. Cross-validation is 
generally not used with neural networks due to the computational cost of the training process (ref?). The remainder, 
the training set, is divided into batches, sizes of which are commonly exponents of 2.

In an iteration of neural network training, a batch, stacked in a tensor of dimension one larger than the dataset, 
is passed through the network: outputs are computed based on the training inputs with the feed forward process.
After this, a loss function is used to evaluate the quality of the output: the loss function maps the network output and 
the correct output recorded in the training batch and outputs a scalar value, small value denoting a good 
match. Loss functions used in optical character recognition are presented in Section~\ref{sect:loss_funcs}.
After this follows a step called backpropagation: the gradient of the loss function with respect 
to the neural network weights is computed. The algorithm used in this computation is called automatic differentiation,
and is able to compute gradients with equal computational complexity as the feed forward by utilizing 
a variant of the chain rule and by proceeding backward in the network \cite{princebook}.

Once the gradient is computed, the next step is to choose how to adjust the network weights 
based on the gradient information. The simplest approach is, given a predefined step size 
known as the learning rate, to adjust the weights by the magnitude of the learning rate 
in the direction of fastest decreasing gradient, a heuristic called gradient descent. Different options for this approach 
are generally called optimizers and finding a suitable one is a fairly complex problem.
Other known optimizers are stochastic gradient descent (SGD), that inserts randomness 
to the weight-adjusting steps, and Adam (Adaptive Moment Estimation), that 
uses moments or gradients obtained in previous steps to add smoothness to the 
movement trajectory \cite{princebook}. After a weight-adjusting step is completed 
with the optimizer, the training iteration is completed.

The training process consists of repeatedly performing the aforementioned training 
iterations. Once the all batches of the whole dataset are used for training,
a training step known as epoch is completed. An usual a training process 
completes dozens or hundreds of epochs. The training is terminated once a predefined 
stopping condition, such as a number of epochs or a sufficiently small gradient 
magnitude, is met. The goal of the training process is to find the global minimum of the loss 
function with respect to the network weights, as this setting would correspond to 
the optimal approximation of the input-output mapping. Like with optimizers, 
determining optimal stopping conditions is a difficult problem area within neural network optimization.

After the training is completed, the test dataset laid to the side at the start of 
training is used to evaluate the predictive power of the network on unseen data, 
also known as generalization performance. Metrics for measuring the accuracy 
of a readily-trained model are presented in Section~\ref{sect:eval_metrics}.
At this point the model should be considered 'frozen', as adjusting it would 
optimize the model to the small test set, not the general problem. This pitfall is 
known as 'data leakage' \cite{engbook}.

As is evident from the generality of the previous description, there are numerous 
specific aspects to consider when designing highly accurate neural networks. The 
rest of this chapter presents a snapshot of this problem area, focusing on those 
relevant to our problem of recognizing handwritten characters, and the rest of the 
work will experiment with parts of these aspects. A summarizing pseudocode of the 
neural network training process with gradient descent is presented in Algorithm~\ref{alg:net_training}.

\begin{algorithm}
    \caption{Neural Network Training}
    \begin{algorithmic}[1]
        \State \textbf{Input:} training\_data, epochs, learning\_rate
        \State Initialize weights $W$ randomly
        \State Initialize biases $b$ randomly
        
        \For{epoch = 1 to epochs}
            \For{each (input, target) in training\_data}
                \State $output \gets \text{ForwardPropagation}(input, W, b)$
                \State $loss \gets \text{CalculateLoss}(output, target)$
                \State $(gradients\_W, gradients\_b) \gets \text{BackwardPropagation}(input, output, target, W, b)$
                \State $W \gets W - learning\_rate \times gradients\_W$
                \State $b \gets b - learning\_rate \times gradients\_b$
            \EndFor
            \State Print("Epoch:", epoch, "Loss:", loss)
        \EndFor
        
        \State \textbf{Output:} $W, b$  \Comment{Trained weights and biases}
    \end{algorithmic}
    \label{alg:net_training}
\end{algorithm}

\subsubsection{Loss functions}
\label{sect:loss_funcs}

Loss functions are needed within the neural network training process to evaluate the model output 
quality in each training iteration. These functions map two equally shaped inputs, the predicted 
and true labels, to a scalar value describing match quality, a low value representing a good match \cite{princebook}. 
Thus, for instance, the simple function $f: x,y \rightarrow |x-y|$  would qualify as a loss function.
The most commonly used loss functions in optical character recognition are cross-entropy for 
character classification and the CTC loss for sequence learning.

Loss functions are constructed usin maximum likelihood estimation. When one frames the neural network as outputting 
a conditional distribution $P(y|X)$, $y$ being the network output and $X$ the input, each correct label in the 
training set should have a high probability in this distribution. The likelihood is obtained by taking the product of 
all ground truth label occurence probabilities, and the training goal becomes maximizing this value. Loss functions are derived 
from the maximum likelihood formalization, so that the network parametrization associated with zero loss is equivalent to 
the maximum likelihood parametrization. These derivations are out of scope of this work, but can be found in Prince's book
section 5.7 \cite{princebook} for cross-entropy and the original paper \cite{ctcloss} for the CTC loss.

The cross-entropy loss function maps pairs of class probability vectors 
to a loss value. The model output vector describes the probabilities 
of the input belonging to each of the possible classes and the ground
 truth vector has the correct 
class set to one, and all other probabilities to zero. The loss function $L$ 
is constructed using the Kullback-Leibler divergence between the empirical data distribution $q(y)$,
a point mass distribution of the correct labels,
 and the model output distribution 
$Pr(y|\mathbf{\theta})$:

\begin{align}
    L(\mathbf{\theta})=\int_{-\infty}^{\infty}q(y)\log[q(y)]dy-\int_{-\infty}^{\infty}q(y)\log[Pr(y|\mathbf{\theta})]dy,
\end{align}

where the first term is omitted since it has no dependence on the parameters $\mathbf{\theta}$.
As the distributions are discrete, the loss reduces to

\begin{align}
    L(\mathbf{\theta})=-\sum_{i=1}^{N}\log[Pr(y_i|f(x_i,\mathbf{\theta}))],
\end{align}

where $N$ denotes dataset size, $y_i$ the correct label, and $f(x_i, \mathbf{\theta})$ is the neural network output.

\subsection{Evaluating model performance}
\label{sect:eval_metrics}

Evaluation metrics, numeric values decribing the generalization performance of the trained neural network 
on unseen data, are used to compare which techniques for implementing neural networks tend to 
perform better than others. Using standard metrics 
and benchmark problems, such as the MNIST problem of handwritten digit 
classification, has allowed comparisons across large bodies of research.

The most common evaluation metrics used when classifying handwritten symbols are accuracy and the F1 score.
Accuracy score simply notes the percentage of test images that were classified to the correct class, expressed 
as a number between zero and one. The main deficiency of using accuracy is brought to light when 
considering a problem where the probabilities of a class being correct are highly uneven. This is the case in many 
medical cases: for instance in a cancer screening, one in 500 patients, 0.2 percent, could have cancer.
A dummy classifier stating everyone to be healthy would achieve a stellar accuracy of 0.998, but is clearly useless.
Any useful model should outperform the dummy, thus comparisons between classifiers would be needed to made 
between values from 0.998 to 1.00, a rather inconvenient range.

The metrics of precision, recall and F1 are used in these cases. Precision measures the 
fraction of true positives identified by the model, recall the fraction of true positives out 
of positives detected by the model. The always-healthy dummy cancer classifier would score zero 
for both metrics, better describing the uselessness of the approach. The F1 score is the harmonic mean of these 
scores:

\begin{align}
    F1 = 2 \times \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\end{align}

For the case of classifying dental markings, the accuracy score is used as the evaluation metric, 
since the distribution of occurences of different tooth types are not highly uneven.
As the same case applies to most other handwritten symbol classification problems, previous work is 
also compared using the accuracy score.

\section{Architectures}

\subsection{Convolutional layers}

\subsection{Transformers}

\subsection{Autoencoders}

\section{Techniques and heuristics for improving performance}

\section{Transfer learning}

\subsection{Foundation models}


\chapter{Related work}

\chapter{Experimental setup}

\chapter{Results and discussion}

\chapter{Conclusions\label{chapter:conclusions}}


% STEP 5:
% Uncomment the following lines and set your .bib file and desired bibliography style
% to make a bibliography with BibTeX.
% Alternatively you can use the thebibliography environment if you want to add all
% references by hand.

\cleardoublepage %fixes the position of bibliography in bookmarks
\phantomsection

\addcontentsline{toc}{chapter}{\bibname} % This lines adds the bibliography to the ToC
\bibliographystyle{abbrv} % numbering alphabetic order
\bibliography{bibliography}

\end{document}
