\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage[style=numeric,bibstyle=numeric,backend=biber,natbib=true,maxbibnames=99,giveninits=true,uniquename=init]{biblatex}

\addbibresource{../bibliography.bib}
\title{Thesis notes}

\begin{document}

\tableofcontents

\section{Introduction}

\section{background}

\subsection{neural networks and deep learning}
keywords to explain (maybe) from \cite{li2021trocr}
- knowledge distillation
- generalist models
	- large unsupervised training data sets
- transformers
- cnns
- deep neural networks
- self attention
- convolution
- transfer learning
- encoder/decoder
- model compression
- loss functions
	- cross-entropy 
- data augmentation
- training/validation/test data sets
- learning rate
- batch size
- tokenizing
- image patches
- self-attention
- multi-head self-attention
- performance metrics
	- precision
	- recall 
	- f1

\subsection{paleoecology}

\section{data methods etc}

things to try
data augmentation

\section{results}

\section{conclusion}

\printbibliography

\end{document}